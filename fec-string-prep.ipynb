{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "from time import sleep\n",
    "import sys\n",
    "os.environ['PATH'] += \";C\\Program Files\\Git\\\\bin\"\n",
    "\n",
    "'''# ---------------- Old Toolbar Updated -------------------------#\n",
    "toolbar_width = 40\n",
    "\n",
    "# setup toolbar\n",
    "sys.stdout.write(\"[%s]\" % (\" \" * toolbar_width))\n",
    "sys.stdout.flush()\n",
    "sys.stdout.write(\"\\b\" * (toolbar_width+1)) \n",
    "'''\n",
    "\n",
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "def progbar(i,j):\n",
    "    sys.stdout.write('\\r')\n",
    "    k = round((i / j) * 100,2)\n",
    "    sys.stdout.write(\"%d%%\" % k)\n",
    "    sys.stdout.flush()\n",
    "    sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#rm -rf fec-data\n",
    "#git clone git@github.com:jbisbee1/fec-data.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commit 0549573e24b8e24eaf542ef52cbbe2f8d14204de\n",
      "Author: jbisbee1 <jimbisbee@yahoo.com>\n",
      "Date:   Fri Jul 22 15:40:43 2016 -0400\n",
      "\n",
      "    Updated Qualtrics import .txt file with earmarks firms.\n",
      "\n",
      "commit fd0054cc07e492fb2f0aa3389652e3f5f8635dd5\n",
      "Author: jbisbee1 <jimbisbee@yahoo.com>\n",
      "Date:   Fri Jul 22 09:27:10 2016 -0400\n",
      "\n",
      "    Implementing fuzzy wuzzy and using it to create Qualtrics surveys for manual checking.\n",
      "\n",
      "commit 4cd451b67957990f506074a7f38e200ceb053862\n",
      "Author: jbisbee1 <jimbisbee@yahoo.com>\n",
      "Date:   Thu Jul 21 16:37:22 2016 -0400\n",
      "\n",
      "    Updated the readme.md file to remind myself of fuzzyfuzzy.\n",
      "\n",
      "commit 3f7beb7944abf2f86654fc6b9c15fcfdb61f4091\n",
      "Author: jbisbee1 <jimbisbee@yahoo.com>\n",
      "Date:   Thu Jul 21 12:15:12 2016 -0400\n",
      "\n",
      "    Updated the readme.md file with a brief description of the purpose for this repository.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_recipient</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! A+ TUTOR U LEARNIGN CENTERS OF CENTRAL FLORI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!1T Family Dental</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!2 Technologies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"33\" Ranch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Concept\" Employees Of</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       raw_recipient  n\n",
       "0  ! A+ TUTOR U LEARNIGN CENTERS OF CENTRAL FLORI...  1\n",
       "1                                  !1T Family Dental  3\n",
       "2                                    !2 Technologies  1\n",
       "3                                         \"33\" Ranch  1\n",
       "4                             \"Concept\" Employees Of  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipients = pd.read_stata(\"../../rawrecipients.dta\")\n",
    "recipients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy matching on firm names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the fuzzywuzzy package and run through each firm name, comparing it to the remaining 5.6 million in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#pip install \"C:/Users/jhb362/Dropbox/Programs/python_Levenshtein-0.12.0-cp35-none-win_amd64.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ! A+ TUTOR U LEARNIGN CENTERS OF CENTRAL FLORI...\n",
       "1                                    !1T Family Dental\n",
       "2                                      !2 Technologies\n",
       "3                                           \"33\" Ranch\n",
       "4                               \"Concept\" Employees Of\n",
       "Name: raw_recipient, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recclean = recipients['raw_recipient']\n",
    "recclean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the firm names is compared against a master list which is stripped of any non-string types (although I'm not sure why any would be in there, there seem to be a few.) I also drop duplicates but, again, I don't think there should be too many in there, given all the work already conducted using Stata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniques = recclean.drop_duplicates()\n",
    "select = [isinstance(e,str) for e in uniques]\n",
    "uniques2 = uniques[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5647972 5647972\n"
     ]
    }
   ],
   "source": [
    "select = [isinstance(e,str) for e in recclean]\n",
    "recclean2 = recclean[select]\n",
    "print(len(recclean2), len(uniques2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmed that there are no duplicates in the list. \n",
    "\n",
    "Now we're off to the races. This is going to take a goddamned long time so smoke 'em if you got 'em. We go through every firm name in the full list of 5.6m and compare the string to all of the others using the fuzzywuzzy method \"process\". \n",
    "\n",
    "Whoa...too long. I'm going to try and run this on the cluster. No sense in gumming up my machine."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pairings={}\n",
    "counter = 0\n",
    "for rec in recclean2:\n",
    "    pairings[rec]=process.extractBests(rec,uniques2,scorer=fuzz.token_set_ratio,score_cutoff=92)\n",
    "    progbar(counter,len(recclean2)-1)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "mask = [list(pairings.items())[i] for i in range(0,len(list(pairings.items()))) if len(list(pairings.items())[i][1]) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a .txt file in the format for importing to Qualtrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below can be converted to illustrate the process by which I create the .txt files that are formatted to be imported into Qualtrics. I don't run the code here though because it would take a long time."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "submask = mask[:20]\n",
    "counter = 0\n",
    "for j in range(0,len(submask),10):\n",
    "    print(\"Block Test: %s\" % counter)\n",
    "    for k in range(0,len(submask[j:j+10])):\n",
    "        print(\"Advanced Choices: %s\" % submask[k][0] + \" %s\" % counter)\n",
    "        for i in range(1,len(submask[k][1])):\n",
    "            print(\"Choice: %s\" % i + \" %s\" % submask[k][1][i][0])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "max = round(len(mask) % 100,0)\n",
    "start = 0\n",
    "for z in range(1,max):\n",
    "    end = z*100\n",
    "    submask = mask[start:z*100]\n",
    "    start = z*100+1\n",
    "    survey_file = open(\"survey-test-%s\" %z +\".txt\",\"w\")\n",
    "    survey_file.write(\"[[AdvancedFormat]] \\n\\n\")\n",
    "    counter = 0\n",
    "    for j in range(0,len(submask),10):\n",
    "        survey_file.write(\"[[Block: Firm Names - %s\" % counter + \"]]\\n\")\n",
    "        for k in range(0,len(submask[j:j+10])):\n",
    "            survey_file.write(\"[[Question:MC:MultipleAnswer:Vertical]] \\n \\\n",
    "            %s\" % submask[k][0].upper() + \"\\n\\n\")\n",
    "            survey_file.write(\"[[AdvancedChoices]] \\n\")\n",
    "            for i in range(1,len(submask[k][1])):\n",
    "                survey_file.write(\"[[Choice: %s\" % i +\"]] \\n \\\n",
    "                %s\" % submask[k][1][i][0].upper() +'\\n')\n",
    "            survey_file.write(\"\\n\")\n",
    "        counter +=1\n",
    "    survey_file.close()\n",
    "    \n",
    "    # update the bar\n",
    "    sys.stdout.write(\"-\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up-to-date with 'origin/master'.\n",
      "Changes to be committed:\n",
      "  (use \"git reset HEAD <file>...\" to unstage)\n",
      "\n",
      "\tmodified:   fec-string-prep.ipynb\n",
      "\tnew file:   survey-test.txt\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t.ipynb_checkpoints/\n",
      "\n",
      "[master 0549573] Updated Qualtrics import .txt file with earmarks firms.\n",
      " 2 files changed, 6352 insertions(+), 227 deletions(-)\n",
      " create mode 100644 survey-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git add fec-string-prep.ipynb\n",
    "git add survey-test.txt\n",
    "git status\n",
    "git commit -m \"Wrote progress bar % tracker and merged firm names for lobbying, earmarks, grants, contracts, and FEC. Goddamned FEC slows the bastard to a crawl. I also didn't manage to get anything done on the legal dataset which, unfortunately, lists defendents together in a single cell, separated by commas. Stupidly, this dataset also uses the LNAME, FNAME format for individual defendents, making extraction a real bear.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
