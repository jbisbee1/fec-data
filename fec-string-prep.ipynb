{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import timeit\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "from time import sleep\n",
    "import sys\n",
    "#os.environ['PATH'] += \";C\\Program Files\\Git\\\\bin\"\n",
    "\n",
    "'''# ---------------- Old Toolbar Updated -------------------------#\n",
    "toolbar_width = 40\n",
    "\n",
    "# setup toolbar\n",
    "sys.stdout.write(\"[%s]\" % (\" \" * toolbar_width))\n",
    "sys.stdout.flush()\n",
    "sys.stdout.write(\"\\b\" * (toolbar_width+1)) \n",
    "'''\n",
    "\n",
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "def progbar(i,j):\n",
    "    sys.stdout.write('\\r')\n",
    "    k = round((i / j) * 100,2)\n",
    "    sys.stdout.write(\"%d%%\" % k)\n",
    "    sys.stdout.flush()\n",
    "    sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#rm -rf fec-data\n",
    "#git clone git@github.com:jbisbee1/fec-data.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_recipient</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! A+ TUTOR U LEARNIGN CENTERS OF CENTRAL FLORI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!1T Family Dental</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!2 Technologies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"33\" Ranch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Concept\" Employees Of</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       raw_recipient  n\n",
       "0  ! A+ TUTOR U LEARNIGN CENTERS OF CENTRAL FLORI...  1\n",
       "1                                  !1T Family Dental  3\n",
       "2                                    !2 Technologies  1\n",
       "3                                         \"33\" Ranch  1\n",
       "4                             \"Concept\" Employees Of  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipients = pd.read_stata(\"../../rawrecipients.dta\")\n",
    "recipients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy matching on firm names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the fuzzywuzzy package and run through each firm name, comparing it to the remaining 5.6 million in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#pip install \"C:/Users/jhb362/Dropbox/Programs/python_Levenshtein-0.12.0-cp35-none-win_amd64.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ! A+ TUTOR U LEARNIGN CENTERS OF CENTRAL FLORI...\n",
       "1                                    !1T Family Dental\n",
       "2                                      !2 Technologies\n",
       "3                                           \"33\" Ranch\n",
       "4                               \"Concept\" Employees Of\n",
       "Name: raw_recipient, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recclean = recipients['raw_recipient'][:10000]\n",
    "recclean.head()\n",
    "str(sys.argv)\n",
    "int(sys.argv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the firm names is compared against a master list which is stripped of any non-string types (although I'm not sure why any would be in there, there seem to be a few.) I also drop duplicates but, again, I don't think there should be too many in there, given all the work already conducted using Stata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniques = recclean.drop_duplicates()\n",
    "select = [isinstance(e,str) for e in uniques]\n",
    "uniques2 = uniques[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "select = [isinstance(e,str) for e in recclean]\n",
    "recclean2 = recclean[select]\n",
    "print(len(recclean2), len(uniques2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmed that there are no duplicates in the list. \n",
    "\n",
    "Now we're off to the races. This is going to take a goddamned long time so smoke 'em if you got 'em. We go through every firm name in the full list of 5.6m and compare the string to all of the others using the fuzzywuzzy method \"process\". \n",
    "\n",
    "Whoa...too long. I'm going to try and run this on the cluster. No sense in gumming up my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', ['test akk', 'abs test']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"test\",[x[0] for x in process.extractBests(\"test\",[\"testing\",\"testers\",\"test akk\",\"abs test\"],scorer=fuzz.token_set_ratio,score_cutoff=90)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%"
     ]
    }
   ],
   "source": [
    "pairings=[]\n",
    "counter = 0\n",
    "argstest = 0\n",
    "\n",
    "for rec in recclean2[argstest:argstest+1000]:\n",
    "    pairings.append([rec,[x[0] for x in process.extractBests(rec,\\\n",
    "                                                             uniques2,\\\n",
    "                                                             scorer=fuzz.token_set_ratio,\\\n",
    "                                                             score_cutoff=90)]])\n",
    "    progbar(counter,1000-1)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367 84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['!1T Family Dental', ['1st Family Dental']],\n",
       " ['!2 Technologies', ['12 Technologies']],\n",
       " ['# 1 BAR', ['19 Bar']],\n",
       " ['#1 CLEANERS', ['$1.25 CLEANERS']],\n",
       " ['#1 Cochran', ['1 Cochran']],\n",
       " ['#1 Mortgage', ['1st Mortgage']],\n",
       " ['#1 SUN TAN AND TRAVEL, INC.', ['#1 SUN TAN & TRAVEL INC.']],\n",
       " ['#2 Downing Place', ['2 Downing Place']],\n",
       " ['#2 LA NAILS', ['#2 LA NAIL']],\n",
       " ['#7 STEAK-N-TAKE RESTAURANT', ['#7 STEAK-N-TAKE RESTARUANT']],\n",
       " ['#9 AREA VOLUNTEER FIRE DEPARTMENT', ['#9 AREA VOL. FIRE DEPARTMENT']],\n",
       " ['$ 1.49 DRY CLEAN CITY # 9',\n",
       "  ['$1 69 DRY CLEAN CITY', '$1.69 DRY CLEAN CITY', '$1.50 DRY CLEAN CITY']],\n",
       " ['$1 69 DRY CLEAN CITY', ['$1.69 DRY CLEAN CITY', '$1.79 DRY CLEAN CITY']],\n",
       " ['$1.00 DOLLAR STORE', ['$1 DOLLAR STORE']],\n",
       " ['$1.25 CLEANERS', ['#1 CLEANERS', '$1.25 DRY-CLEANERS']],\n",
       " ['$1.25 DRY CLEAN CENTER, INC.',\n",
       "  ['$1.25 DRY CLEAN SUPER CENTER', '1.25 DRY CLEAN SUPER CENTER']],\n",
       " ['$1.25 DRY CLEAN SUPER CENTER',\n",
       "  ['1.25 DRY CLEAN SUPER CENTER',\n",
       "   '1.25 DRY CLEAN SUPER CENTER OF',\n",
       "   '$1.49 DRY CLEAN SUPER CENTER']],\n",
       " ['$1.25 DRY-CLEANERS', ['$1.25 CLEANERS']],\n",
       " ['$1.49 DRY CLEAN SUPER CENTER',\n",
       "  ['$1.25 DRY CLEAN SUPER CENTER',\n",
       "   '1.25 DRY CLEAN SUPER CENTER',\n",
       "   '1.25 DRY CLEAN SUPER CENTER OF']],\n",
       " ['$1.50 CLEANERS', ['$1.25 CLEANERS', '$1.59 CLEANERS', '#1 CLEANERS']],\n",
       " ['$1.50 DRY CLEAN CITY',\n",
       "  ['1.50 DRY CLEAN CITY',\n",
       "   '$1 69 DRY CLEAN CITY',\n",
       "   '$ 1.49 DRY CLEAN CITY # 9']],\n",
       " ['$1.59 CLEANERS', ['$1.25 CLEANERS', '$1.50 CLEANERS', '#1 CLEANERS']],\n",
       " ['$1.69 CLEANERS', ['$1.59 CLEANERS', '#1 CLEANERS']],\n",
       " ['$1.69 DRY CLEAN CITY', ['$1 69 DRY CLEAN CITY', '$1.79 DRY CLEAN CITY']],\n",
       " ['$1.69 DRY CLEAN USA', ['$1.69 DRY CLEAN USA 2', '$1.79 DRY CLEAN USA']],\n",
       " ['$1.69 DRY CLEAN USA 2', ['$1.69 DRY CLEAN USA']],\n",
       " ['$1.75 CLEANERS', ['$1.25 CLEANERS', '#1 CLEANERS', '$1.75 CLEANERS MAX']],\n",
       " ['$1.75 CLEANERS MAX', ['$1.75 CLEANERS']],\n",
       " ['$1.79 DRY CLEAN CITY',\n",
       "  ['$1 69 DRY CLEAN CITY',\n",
       "   '$1.69 DRY CLEAN CITY',\n",
       "   '$ 1.49 DRY CLEAN CITY # 9']],\n",
       " ['$1.79 DRY CLEAN USA', ['$1.69 DRY CLEAN USA', '$1.69 DRY CLEAN USA 2']],\n",
       " ['$1.99 DRY CLEANERS', ['1 95 DRY CLEANERS']],\n",
       " ['$200', ['200']],\n",
       " ['$2100$ REALTY', ['100% Realty', '210 Realty']],\n",
       " [\"$ACK 'N' $AVE\", [\"$ACK 'N $AVE\"]],\n",
       " ['& FARMER', ['/FARMER']],\n",
       " ['& R. MARTINEK DBA SEA ESCAPE', ['&R.MARTINEK DBA SEA ESCAPE']],\n",
       " ['& RANCHER', ['/RANCHER']],\n",
       " ['& VENDING', [', & J VENDING']],\n",
       " ['& VOLUNTEER', ['/VOLUNTEER']],\n",
       " ['&R.MARTINEK DBA SEA ESCAPE', ['& R. MARTINEK DBA SEA ESCAPE']],\n",
       " [\"'98 Leadership PAC\", [\"'96 Leadership PAC\"]],\n",
       " [\"'AHA PUNANA LEO, INC.\", [\"'AHA PUNANA LEO, INC\"]],\n",
       " [\"'D' STREET MARKET\", ['10TH STREET MARKET']],\n",
       " [\"'TIS THE SEASON, INC\", [\"'TIS THE SEASON\"]],\n",
       " ['(Alternate) City of West Richland', ['(Alternate) City of Richland']],\n",
       " ['(Alternate) Washington State University',\n",
       "  ['(Alternate) University of Washington']],\n",
       " ['(BEST EFFORT)',\n",
       "  ['*BEST EFFORT', '- BEST EFFORT', '(BEST EFFORTS)', '*BEST EFFORTS']],\n",
       " ['(BEST EFFORTS)',\n",
       "  ['*BEST EFFORTS', '(BEST EFFORT)', '*BEST EFFORT', '- BEST EFFORT']],\n",
       " ['(ILLEGIBLE) ASSOCIATES INC', ['(ILLEGIBLE) ASSOCIATES']],\n",
       " ['(ILLEGIBLE)(ILLEGIBLE)', ['(ILLEGIBLE) (ILLEGIBLE)']],\n",
       " ['(THE) GRAPE AND BEAN', ['(THE) GRAPE & BEAN']],\n",
       " [\"(THE) OUTPOST CAFE'\", ['(THE) OUTPOST CAFE CO.']],\n",
       " ['(THE) TIDES, INC.', ['(THE) TIDES INC.']],\n",
       " ['* REFUND-NOT A CONTRIBUTION', ['*REFUND-NOT A CONTRIBUTION']],\n",
       " ['*BEST EFFORT',\n",
       "  ['(BEST EFFORT)', '- BEST EFFORT', '(BEST EFFORTS)', '*BEST EFFORTS']],\n",
       " ['*BEST EFFORTS',\n",
       "  ['(BEST EFFORTS)', '(BEST EFFORT)', '*BEST EFFORT', '- BEST EFFORT']],\n",
       " ['*INGHAM CTY CLERK', ['*INGHAM COUNTY CLERK']],\n",
       " ['*J & T VENDING', [', & J VENDING']],\n",
       " ['*MI DEPT OF TREASURY', ['/DEPT OF TREASURY']],\n",
       " ['*REFUND-NOT A CONTRIBUTION', ['* REFUND-NOT A CONTRIBUTION']],\n",
       " [', & J VENDING', ['*J & T VENDING', '& VENDING']],\n",
       " ['- BEST EFFORT',\n",
       "  ['(BEST EFFORT)', '*BEST EFFORT', '(BEST EFFORTS)', '*BEST EFFORTS']],\n",
       " ['- HERZOG & RHOADS INC', ['- HERZOG & RHOADS']],\n",
       " ['.COM REAL ESTATE', ['/ REAL ESTATE']],\n",
       " ['/ DUKE ENERGY', ['/  DUKE ENERGY']]]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = []\n",
    "for j in range(len(pairings)):\n",
    "    new.append([pairings[j][0],[i for i in pairings[j][1] if pairings[j][0] != i]])\n",
    "mask = [new[i] for i in range(len(new)) if len(new[i][1]) > 0]\n",
    "\n",
    "new2 = []\n",
    "for j in range(len(mask)):\n",
    "    new2.append([mask[j][0],[x[0] for x in process.extractBests(mask[j][0],\\\n",
    "                                                                mask[j][1],\\\n",
    "                                                                scorer = fuzz.token_sort_ratio,\\\n",
    "                                                                score_cutoff=85)]])\n",
    "mask2 = [new2[i] for i in range(len(new2)) if len(new2[i][1]) > 0]\n",
    "print(len(mask),len(mask2))\n",
    "\n",
    "forsurvey=[]\n",
    "for i in range(len(mask2)-1):\n",
    "    if len(mask2[i][1]) == 1:\n",
    "        j = i+1\n",
    "        if [mask2[i][0],mask2[i][1][0]] != [mask2[j][1][0],mask2[j][0]]:\n",
    "            forsurvey.append(mask2[i])\n",
    "    else:\n",
    "        forsurvey.append(mask2[i])\n",
    "forsurvey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a .txt file in the format for importing to Qualtrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below can be converted to illustrate the process by which I create the .txt files that are formatted to be imported into Qualtrics. I don't run the code here though because it would take a long time."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "submask = mask[:20]\n",
    "counter = 0\n",
    "for j in range(0,len(submask),10):\n",
    "    print(\"Block Test: %s\" % (j / 10))\n",
    "    for k in range(j,j+10):\n",
    "        print(\"     Advanced Choices: %s\" % submask[k][0] + \" %s\" % counter)\n",
    "        for i in range(0,len(submask[k][1])):\n",
    "            print(\"          Choice: %s\" % i + \" %s\" % submask[k][1][i])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "60%"
     ]
    }
   ],
   "source": [
    "maxs = int(math.ceil(len(forsurvey) / 100))\n",
    "print(maxs)\n",
    "length = len(forsurvey)\n",
    "\n",
    "start = 0\n",
    "counter = 0\n",
    "\n",
    "for z in range(1,maxs+1):\n",
    "    end = min(z*100,length)\n",
    "    submask = forsurvey[start:end]\n",
    "    start = end+1\n",
    "    survey_file = open(\"survey-test-%s\" %z +\".txt\",\"w\")\n",
    "    survey_file.write(\"[[AdvancedFormat]] \\n\\n\")\n",
    "    for j in range(0,len(submask),10):\n",
    "        survey_file.write(\"[[Block: Firm Names - %s\" % counter + \"]]\\n\")\n",
    "        for k in range(j,min(j+10,len(submask))):\n",
    "            survey_file.write(\" [[Question:MC:MultipleAnswer:Vertical]] \\n \\\n",
    "            %s\" % submask[k][0].upper() + \"\\n\\n\")\n",
    "            survey_file.write(\"  [[AdvancedChoices]] \\n\")\n",
    "            for i in range(0,len(submask[k][1])):\n",
    "                survey_file.write(\"    [[Choice: %s\" % i +\"]] \\n \\\n",
    "                %s\" % submask[k][1][i].upper() +'\\n')\n",
    "            survey_file.write(\"\\n\")\n",
    "        progbar(counter,maxs*10)\n",
    "        counter += 1\n",
    "    survey_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!1T Family Dental', ['1st Family Dental']]\n",
      "['1st Family Dental']\n"
     ]
    }
   ],
   "source": [
    "crosswalk1 = []\n",
    "bisids=[]\n",
    "for i in range(len(forsurvey)):\n",
    "    crosswalk1.append(forsurvey[i][0])\n",
    "    bisids.append(\"bid\"+str(i))\n",
    "    for j in range(len(forsurvey[i][1])):\n",
    "        crosswalk1.append(forsurvey[i][1][j])\n",
    "        bisids.append(\"bid\"+str(i))\n",
    "\n",
    "crosswalk = pd.DataFrame({'cw1' : crosswalk1[:20],\n",
    " 'bid':bisids[:20]\n",
    "  })\n",
    "print(forsurvey[0])\n",
    "print(forsurvey[0][1])\n",
    "#print(mask[23][1][0][0])\n",
    "\n",
    "#inds = []\n",
    "#for x in range(len(forsurvey)):\n",
    "#    for i in range(len(forsurvey[x][1])):\n",
    "#         if mask[23][1][0] in forsurvey[x][1][i]:\n",
    "#                inds.append(x)\n",
    "#mask[inds[1]]\n",
    "#inds\n",
    "\n",
    "crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = 1\n",
    "name = str('test%s' % args + '.csv')\n",
    "header = ['bid','cw1']\n",
    "crosswalk.to_csv(name,sep=',',columns=header,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is ahead of 'origin/master' by 2 commits.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "Changes to be committed:\n",
      "  (use \"git reset HEAD <file>...\" to unstage)\n",
      "\n",
      "\tmodified:   fec-string-prep.ipynb\n",
      "\tdeleted:    survey-test.txt\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t.ipynb_checkpoints/\n",
      "\tsurvey-test-1.txt\n",
      "\ttest.csv\n",
      "\ttest1.csv\n",
      "\n",
      "[master 4b42c6f] Updated the cluster process. Created crosswalk .csv file in addition to dramatically reducing the number of surveys created.\n",
      " 2 files changed, 291 insertions(+), 4705 deletions(-)\n",
      " delete mode 100644 survey-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n",
      "warning: LF will be replaced by CRLF in fec-string-prep.ipynb.\n",
      "The file will have its original line endings in your working directory.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git add fec-string-prep.ipynb\n",
    "git status\n",
    "git commit -m \"Updated the cluster process. Created crosswalk .csv file in addition to dramatically reducing the number of surveys created.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
